{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Implementation of the DCGAN paper \n* Title **UNSUPERVISED REPRESENTATION LEARNING WITH DEEP CONVOLUTIONAL GENERATIVE ADVERSARIAL NETWORKS**\n* Link to the paper [https://arxiv.org/pdf/1511.06434v2.pdf]","metadata":{}},{"cell_type":"code","source":"!pip install torchsummary\n\nimport os\nimport torch\nimport torch.nn as nn\nfrom torchsummary import summary\n\nimport torch.optim as optim\nimport torchvision\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\nfrom tqdm.auto import tqdm","metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:12:23.852198Z","iopub.execute_input":"2023-05-09T12:12:23.853064Z","iopub.status.idle":"2023-05-09T12:12:39.516718Z","shell.execute_reply.started":"2023-05-09T12:12:23.853018Z","shell.execute_reply":"2023-05-09T12:12:39.515622Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torchsummary\n  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\nInstalling collected packages: torchsummary\nSuccessfully installed torchsummary-1.5.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Discrimnator","metadata":{}},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, channels_img, features_d):\n        super().__init__()\n        self.disc = nn.Sequential(\n            nn.Conv2d(\n                channels_img, features_d, kernel_size=4, stride=2, padding=1\n            ),\n            nn.LeakyReLU(0.2),\n            self._block(features_d, features_d*2, 4, 2, 1),\n            self._block(features_d*2, features_d*4, 4, 2, 1),\n            self._block(features_d*4, features_d*8, 4, 2, 1),\n            nn.Conv2d(features_d*8, 1, kernel_size=4, stride=2, padding=0),\n            nn.Sigmoid(),\n        )\n        \n    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n        return nn.Sequential(\n            nn.Conv2d(\n                in_channels,\n                out_channels,\n                kernel_size,\n                stride,\n                padding,\n                bias=False\n            ),\n            nn.BatchNorm2d(out_channels),\n            nn.LeakyReLU(0.2)\n        )\n    \n    def forward(self, x):\n        return self.disc(x)","metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:12:39.518974Z","iopub.execute_input":"2023-05-09T12:12:39.519718Z","iopub.status.idle":"2023-05-09T12:12:39.530908Z","shell.execute_reply.started":"2023-05-09T12:12:39.519678Z","shell.execute_reply":"2023-05-09T12:12:39.529914Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Generator","metadata":{}},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self, z_dim, channels_img, features_g):\n        super().__init__()\n        self.gen = nn.Sequential(\n            self._block(z_dim, features_g*16, 4, 1, 0),\n            self._block(features_g*16, features_g*8, 4, 2, 1),\n            self._block(features_g*8, features_g*4, 4, 2, 1),\n            self._block(features_g*4, features_g*2, 4, 2, 1),\n            nn.ConvTranspose2d(features_g*2, channels_img, kernel_size=4, stride=2, padding=1),\n            nn.Tanh(),\n        )\n        \n    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n        return nn.Sequential(\n            nn.ConvTranspose2d(\n                in_channels,\n                out_channels,\n                kernel_size,\n                stride,\n                padding,\n                bias=False,\n            ),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n        )\n    \n    def forward(self, x):\n        return self.gen(x)","metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:12:39.532451Z","iopub.execute_input":"2023-05-09T12:12:39.533440Z","iopub.status.idle":"2023-05-09T12:12:39.543428Z","shell.execute_reply.started":"2023-05-09T12:12:39.533408Z","shell.execute_reply":"2023-05-09T12:12:39.542382Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"g = Generator(100,3,64)\nsummary(g, (100,1,1), device='cpu')","metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:12:39.546179Z","iopub.execute_input":"2023-05-09T12:12:39.546550Z","iopub.status.idle":"2023-05-09T12:12:39.911370Z","shell.execute_reply.started":"2023-05-09T12:12:39.546513Z","shell.execute_reply":"2023-05-09T12:12:39.909411Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n   ConvTranspose2d-1           [-1, 1024, 4, 4]       1,638,400\n       BatchNorm2d-2           [-1, 1024, 4, 4]           2,048\n              ReLU-3           [-1, 1024, 4, 4]               0\n   ConvTranspose2d-4            [-1, 512, 8, 8]       8,388,608\n       BatchNorm2d-5            [-1, 512, 8, 8]           1,024\n              ReLU-6            [-1, 512, 8, 8]               0\n   ConvTranspose2d-7          [-1, 256, 16, 16]       2,097,152\n       BatchNorm2d-8          [-1, 256, 16, 16]             512\n              ReLU-9          [-1, 256, 16, 16]               0\n  ConvTranspose2d-10          [-1, 128, 32, 32]         524,288\n      BatchNorm2d-11          [-1, 128, 32, 32]             256\n             ReLU-12          [-1, 128, 32, 32]               0\n  ConvTranspose2d-13            [-1, 3, 64, 64]           6,147\n             Tanh-14            [-1, 3, 64, 64]               0\n================================================================\nTotal params: 12,658,435\nTrainable params: 12,658,435\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 5.81\nParams size (MB): 48.29\nEstimated Total Size (MB): 54.10\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"d = Discriminator(3,64)\nsummary(d, (3,64,64), device='cpu')","metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:12:39.918124Z","iopub.execute_input":"2023-05-09T12:12:39.919037Z","iopub.status.idle":"2023-05-09T12:12:40.021904Z","shell.execute_reply.started":"2023-05-09T12:12:39.918993Z","shell.execute_reply":"2023-05-09T12:12:40.020765Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 64, 32, 32]           3,136\n         LeakyReLU-2           [-1, 64, 32, 32]               0\n            Conv2d-3          [-1, 128, 16, 16]         131,072\n       BatchNorm2d-4          [-1, 128, 16, 16]             256\n         LeakyReLU-5          [-1, 128, 16, 16]               0\n            Conv2d-6            [-1, 256, 8, 8]         524,288\n       BatchNorm2d-7            [-1, 256, 8, 8]             512\n         LeakyReLU-8            [-1, 256, 8, 8]               0\n            Conv2d-9            [-1, 512, 4, 4]       2,097,152\n      BatchNorm2d-10            [-1, 512, 4, 4]           1,024\n        LeakyReLU-11            [-1, 512, 4, 4]               0\n           Conv2d-12              [-1, 1, 1, 1]           8,193\n          Sigmoid-13              [-1, 1, 1, 1]               0\n================================================================\nTotal params: 2,765,633\nTrainable params: 2,765,633\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.05\nForward/backward pass size (MB): 2.31\nParams size (MB): 10.55\nEstimated Total Size (MB): 12.91\n----------------------------------------------------------------\n","output_type":"stream"}]},{"cell_type":"code","source":"def initialize_weights(model):\n    for m in model.modules():\n        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n            nn.init.normal_(m.weight.data, 0.0, 0.02)","metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:12:40.023606Z","iopub.execute_input":"2023-05-09T12:12:40.023977Z","iopub.status.idle":"2023-05-09T12:12:40.029731Z","shell.execute_reply.started":"2023-05-09T12:12:40.023922Z","shell.execute_reply":"2023-05-09T12:12:40.028677Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Hyperparameters","metadata":{}},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nlr = 2e-4\nbatch_size = 128\nimage_size = 64\nchannels_img = 1\nz_dim = 100\nnum_epochs = 6\nfeatures_disc = 64\nfeatures_gen = 64","metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:12:48.171566Z","iopub.execute_input":"2023-05-09T12:12:48.172073Z","iopub.status.idle":"2023-05-09T12:12:48.180162Z","shell.execute_reply.started":"2023-05-09T12:12:48.172026Z","shell.execute_reply":"2023-05-09T12:12:48.177423Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose(\n    [\n        transforms.Resize(image_size),\n        transforms.ToTensor(),\n        transforms.Normalize(\n            mean=[0.5 for _ in range(channels_img)],\n            std=[0.5 for _ in range(channels_img)]\n        ),\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:12:49.045292Z","iopub.execute_input":"2023-05-09T12:12:49.045665Z","iopub.status.idle":"2023-05-09T12:12:49.051808Z","shell.execute_reply.started":"2023-05-09T12:12:49.045633Z","shell.execute_reply":"2023-05-09T12:12:49.050631Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Dataset to train on\ndataset = datasets.MNIST(root='dataset/', train=True, transform=transform, download=True)\n# dataset = datasets.ImageFolder(root='/kaggle/input/celeba-dataset/img_align_celeba/', transform=transform)\nloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Inititate generator and discriminator\ngen = Generator(z_dim, channels_img, features_gen).to(device)\ndisc = Discriminator(channels_img, features_disc).to(device)\n\n# Initialize weights of generator and discriminator\ninitialize_weights(gen)\ninitialize_weights(disc)\n\n# Optimizer\nopt_gen = optim.Adam(gen.parameters(), lr=lr, betas=(0.5, 0.999))\nopt_disc = optim.Adam(disc.parameters(), lr=lr, betas=(0.5, 0.999))\n\n# Loss function\ncriterion = nn.BCELoss()","metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:12:55.071519Z","iopub.execute_input":"2023-05-09T12:12:55.072141Z","iopub.status.idle":"2023-05-09T12:12:55.300576Z","shell.execute_reply.started":"2023-05-09T12:12:55.072102Z","shell.execute_reply":"2023-05-09T12:12:55.299527Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Generate a fixed noise of 32x100x1x1 dim to produce 32 images\nfixed_noise = torch.randn(32, z_dim, 1, 1).to(device)\nwriter_real = SummaryWriter(f\"logs/real\")\nwriter_fake = SummaryWriter(f\"logs/fake\")\nstep = 0","metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:12:56.970240Z","iopub.execute_input":"2023-05-09T12:12:56.970849Z","iopub.status.idle":"2023-05-09T12:13:03.452345Z","shell.execute_reply.started":"2023-05-09T12:12:56.970811Z","shell.execute_reply":"2023-05-09T12:13:03.451193Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Clear any logs from previous runs\n!rm -rf ./logs/ \n!mkdir ./logs/","metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:12:44.132525Z","iopub.status.idle":"2023-05-09T12:12:44.133463Z","shell.execute_reply.started":"2023-05-09T12:12:44.133195Z","shell.execute_reply":"2023-05-09T12:12:44.133222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Models","metadata":{}},{"cell_type":"code","source":"gen.train()\ndisc.train()\n\nfor epoch in range(num_epochs):\n    for batch_idx, (real, _) in enumerate(tqdm(loader)):\n        real = real.to(device)\n        noise = torch.randn((batch_size, z_dim, 1, 1)).to(device)\n        fake = gen(noise)\n        # Train disc\n        disc_real = disc(real).reshape(-1)\n        loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n        disc_fake  = disc(fake).reshape(-1)\n        loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n        loss_disc = (loss_disc_real+loss_disc_fake) / 2\n        disc.zero_grad()\n        loss_disc.backward(retain_graph=True)\n        opt_disc.step()\n        \n        # Train generator\n        output = disc(fake).reshape(-1)\n        loss_gen = criterion(output, torch.ones_like(output))\n        gen.zero_grad()\n        loss_gen.backward()\n        opt_gen.step()\n        \n        if batch_idx  % 100 == 0:\n            print(\n                f\"Epoch [{epoch+1}/{num_epochs}] Batch {batch_idx}/{len(loader)}\\\n                            Loss D: {loss_disc:.4f}, loss G: {loss_gen:.4f}\"\n            )\n            with torch.no_grad():\n                fake = gen(fixed_noise)\n                img_grid_real = torchvision.utils.make_grid(\n                    real[:32], normalize=True\n                )\n                img_grid_fake = torchvision.utils.make_grid(\n                    fake[:32], normalize=True\n                )\n                \n                writer_real.add_image(\"Real\", img_grid_real, global_step=step)\n                writer_fake.add_image(\"Fake\", img_grid_fake, global_step=step)\n                step += 1 ","metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:12:44.134903Z","iopub.status.idle":"2023-05-09T12:12:44.135781Z","shell.execute_reply.started":"2023-05-09T12:12:44.135510Z","shell.execute_reply":"2023-05-09T12:12:44.135543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loggin results in tensorboard in Kaggle","metadata":{}},{"cell_type":"code","source":"%%capture\nimport tensorflow as tf \n\n# Download and Intall ngrok\n!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n!unzip ngrok-stable-linux-amd64.zip\n\n# Ngrok Auth token from \n!./ngrok authtoken 2M638sfkbJZrfvgdQ6pDXNo1DdI_57CXbDv7C2p2cEJF3fip8\n","metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:12:44.137231Z","iopub.status.idle":"2023-05-09T12:12:44.138109Z","shell.execute_reply.started":"2023-05-09T12:12:44.137832Z","shell.execute_reply":"2023-05-09T12:12:44.137857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!kill $(lsof -t -i:6006)","metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:12:44.139487Z","iopub.status.idle":"2023-05-09T12:12:44.141326Z","shell.execute_reply.started":"2023-05-09T12:12:44.141054Z","shell.execute_reply":"2023-05-09T12:12:44.141081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run tensorboard as well as Ngrox (for tunneling as non-blocking processes)\nimport os\nimport multiprocessing\n\npool = multiprocessing.Pool(processes = 10)\nresults_of_processes = [pool.apply_async(os.system, args=(cmd, ), callback = None )\n                        for cmd in [f\"tensorboard --logdir ./logs/ --host 0.0.0.0 --port 6006 &\",\n                        \"./ngrok http 6006 &\"]]","metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:12:44.142822Z","iopub.status.idle":"2023-05-09T12:12:44.143678Z","shell.execute_reply.started":"2023-05-09T12:12:44.143415Z","shell.execute_reply":"2023-05-09T12:12:44.143441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run to get ngrok port forwarded website\n! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:12:44.145184Z","iopub.status.idle":"2023-05-09T12:12:44.146037Z","shell.execute_reply.started":"2023-05-09T12:12:44.145750Z","shell.execute_reply":"2023-05-09T12:12:44.145776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save the Models of Generator and Discriminator to memory","metadata":{}},{"cell_type":"code","source":"from pathlib import Path\ndef save_model(model: torch.nn.Module,\n               target_dir: str,\n               model_name: str):\n    # Create target directory\n    target_dir_path = Path(target_dir)\n    target_dir_path.mkdir(parents=True,\n                        exist_ok=True)\n\n    # Create model save path\n    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n    model_save_path = target_dir_path / model_name\n\n    # Save the model state_dict()\n    print(f\"[INFO] Saving model to: {model_save_path}\")\n    torch.save(obj=model.state_dict(),\n             f=model_save_path)","metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:12:44.147527Z","iopub.status.idle":"2023-05-09T12:12:44.148379Z","shell.execute_reply.started":"2023-05-09T12:12:44.148113Z","shell.execute_reply":"2023-05-09T12:12:44.148140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save generator\nsave_model(gen, '', 'generator-1.pth')\n\n# Save Discriminator\nsave_model(disc, '', 'discriminator-1.pth')","metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:12:44.149823Z","iopub.status.idle":"2023-05-09T12:12:44.150673Z","shell.execute_reply.started":"2023-05-09T12:12:44.150406Z","shell.execute_reply":"2023-05-09T12:12:44.150433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate Fake Images using generator and save them to directory","metadata":{}},{"cell_type":"code","source":"# Load generator and discriminator\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ngenerator = Generator(z_dim, channels_img, features_gen).to(device)\ndiscriminator = Discriminator(channels_img, features_disc).to(device)\ngenerator.load_state_dict(torch.load('generator-1.pth'))\ndiscriminator.load_state_dict(torch.load('discriminator-1.pth'))","metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:12:44.152149Z","iopub.status.idle":"2023-05-09T12:12:44.152996Z","shell.execute_reply.started":"2023-05-09T12:12:44.152712Z","shell.execute_reply":"2023-05-09T12:12:44.152739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a noise vector of shape 1x100x1x1 to create a single image and 32x100x1x1 to create 32 images etc\n\nnoise_image = torch.randn(1,100,1,1).to(device)\n\nimage_generated = generator(noise_image)","metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:12:44.154469Z","iopub.status.idle":"2023-05-09T12:12:44.155326Z","shell.execute_reply.started":"2023-05-09T12:12:44.155063Z","shell.execute_reply":"2023-05-09T12:12:44.155090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Save the generated images using pillow","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimport uuid\n\n# Make an image directory\nos.makedirs('images', exist_ok=True)\n\n# Convert tensor to pil image\npil_image_generated = transforms.ToPILImage()(image_generated.squeeze(0))\n\n# Save pil image to images directory\npil_image_generated.save(os.path.join('images', f\"generated-{uuid.uuid1()}.jpg\"))","metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:12:44.156802Z","iopub.status.idle":"2023-05-09T12:12:44.157649Z","shell.execute_reply.started":"2023-05-09T12:12:44.157388Z","shell.execute_reply":"2023-05-09T12:12:44.157416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ims = os.listdir('images')\nims","metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:12:44.159112Z","iopub.status.idle":"2023-05-09T12:12:44.159951Z","shell.execute_reply.started":"2023-05-09T12:12:44.159667Z","shell.execute_reply":"2023-05-09T12:12:44.159693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Image.open(os.path.join('images', ims[1]))","metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:12:44.161457Z","iopub.status.idle":"2023-05-09T12:12:44.162320Z","shell.execute_reply.started":"2023-05-09T12:12:44.162057Z","shell.execute_reply":"2023-05-09T12:12:44.162083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir()","metadata":{"execution":{"iopub.status.busy":"2023-05-09T12:12:44.163810Z","iopub.status.idle":"2023-05-09T12:12:44.164693Z","shell.execute_reply.started":"2023-05-09T12:12:44.164414Z","shell.execute_reply":"2023-05-09T12:12:44.164446Z"},"trusted":true},"execution_count":null,"outputs":[]}]}