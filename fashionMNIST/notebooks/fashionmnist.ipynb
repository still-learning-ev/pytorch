{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Data loading and preprocessing"]},{"cell_type":"code","execution_count":137,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-04-03T12:51:43.156360Z","iopub.status.busy":"2023-04-03T12:51:43.155883Z","iopub.status.idle":"2023-04-03T12:51:43.166102Z","shell.execute_reply":"2023-04-03T12:51:43.164952Z","shell.execute_reply.started":"2023-04-03T12:51:43.156275Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/fashionmnist/t10k-labels-idx1-ubyte\n","/kaggle/input/fashionmnist/t10k-images-idx3-ubyte\n","/kaggle/input/fashionmnist/fashion-mnist_test.csv\n","/kaggle/input/fashionmnist/fashion-mnist_train.csv\n","/kaggle/input/fashionmnist/train-labels-idx1-ubyte\n","/kaggle/input/fashionmnist/train-images-idx3-ubyte\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":138,"metadata":{"execution":{"iopub.execute_input":"2023-04-03T12:51:43.416047Z","iopub.status.busy":"2023-04-03T12:51:43.415472Z","iopub.status.idle":"2023-04-03T12:51:43.422492Z","shell.execute_reply":"2023-04-03T12:51:43.421349Z","shell.execute_reply.started":"2023-04-03T12:51:43.416011Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torchvision"]},{"cell_type":"markdown","metadata":{},"source":["## Read the csv image data train and test using pandas"]},{"cell_type":"code","execution_count":139,"metadata":{"execution":{"iopub.execute_input":"2023-04-03T12:51:43.756576Z","iopub.status.busy":"2023-04-03T12:51:43.755409Z","iopub.status.idle":"2023-04-03T12:51:47.849725Z","shell.execute_reply":"2023-04-03T12:51:47.848653Z","shell.execute_reply.started":"2023-04-03T12:51:43.756525Z"},"trusted":true},"outputs":[],"source":["train_data = pd.read_csv('/kaggle/input/fashionmnist/fashion-mnist_train.csv')\n","test_data = pd.read_csv('/kaggle/input/fashionmnist/fashion-mnist_test.csv')"]},{"cell_type":"code","execution_count":140,"metadata":{"execution":{"iopub.execute_input":"2023-04-03T12:51:47.852113Z","iopub.status.busy":"2023-04-03T12:51:47.851745Z","iopub.status.idle":"2023-04-03T12:51:47.868004Z","shell.execute_reply":"2023-04-03T12:51:47.866902Z","shell.execute_reply.started":"2023-04-03T12:51:47.852076Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>pixel1</th>\n","      <th>pixel2</th>\n","      <th>pixel3</th>\n","      <th>pixel4</th>\n","      <th>pixel5</th>\n","      <th>pixel6</th>\n","      <th>pixel7</th>\n","      <th>pixel8</th>\n","      <th>pixel9</th>\n","      <th>...</th>\n","      <th>pixel775</th>\n","      <th>pixel776</th>\n","      <th>pixel777</th>\n","      <th>pixel778</th>\n","      <th>pixel779</th>\n","      <th>pixel780</th>\n","      <th>pixel781</th>\n","      <th>pixel782</th>\n","      <th>pixel783</th>\n","      <th>pixel784</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2 rows × 785 columns</p>\n","</div>"],"text/plain":["   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n","0      2       0       0       0       0       0       0       0       0   \n","1      9       0       0       0       0       0       0       0       0   \n","\n","   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n","0       0  ...         0         0         0         0         0         0   \n","1       0  ...         0         0         0         0         0         0   \n","\n","   pixel781  pixel782  pixel783  pixel784  \n","0         0         0         0         0  \n","1         0         0         0         0  \n","\n","[2 rows x 785 columns]"]},"execution_count":140,"metadata":{},"output_type":"execute_result"}],"source":["train_data.head(2)"]},{"cell_type":"code","execution_count":141,"metadata":{"execution":{"iopub.execute_input":"2023-04-03T12:51:47.870703Z","iopub.status.busy":"2023-04-03T12:51:47.869527Z","iopub.status.idle":"2023-04-03T12:51:47.888974Z","shell.execute_reply":"2023-04-03T12:51:47.887986Z","shell.execute_reply.started":"2023-04-03T12:51:47.870666Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>pixel1</th>\n","      <th>pixel2</th>\n","      <th>pixel3</th>\n","      <th>pixel4</th>\n","      <th>pixel5</th>\n","      <th>pixel6</th>\n","      <th>pixel7</th>\n","      <th>pixel8</th>\n","      <th>pixel9</th>\n","      <th>...</th>\n","      <th>pixel775</th>\n","      <th>pixel776</th>\n","      <th>pixel777</th>\n","      <th>pixel778</th>\n","      <th>pixel779</th>\n","      <th>pixel780</th>\n","      <th>pixel781</th>\n","      <th>pixel782</th>\n","      <th>pixel783</th>\n","      <th>pixel784</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>9</td>\n","      <td>8</td>\n","      <td>...</td>\n","      <td>103</td>\n","      <td>87</td>\n","      <td>56</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>34</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2 rows × 785 columns</p>\n","</div>"],"text/plain":["   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n","0      0       0       0       0       0       0       0       0       9   \n","1      1       0       0       0       0       0       0       0       0   \n","\n","   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n","0       8  ...       103        87        56         0         0         0   \n","1       0  ...        34         0         0         0         0         0   \n","\n","   pixel781  pixel782  pixel783  pixel784  \n","0         0         0         0         0  \n","1         0         0         0         0  \n","\n","[2 rows x 785 columns]"]},"execution_count":141,"metadata":{},"output_type":"execute_result"}],"source":["test_data.head(2)"]},{"cell_type":"markdown","metadata":{},"source":["### Explore some features of the dataset\n"]},{"cell_type":"code","execution_count":142,"metadata":{"execution":{"iopub.execute_input":"2023-04-03T12:51:47.891971Z","iopub.status.busy":"2023-04-03T12:51:47.891553Z","iopub.status.idle":"2023-04-03T12:51:47.900031Z","shell.execute_reply":"2023-04-03T12:51:47.898969Z","shell.execute_reply.started":"2023-04-03T12:51:47.891935Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['label', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6',\n","       'pixel7', 'pixel8', 'pixel9',\n","       ...\n","       'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779', 'pixel780',\n","       'pixel781', 'pixel782', 'pixel783', 'pixel784'],\n","      dtype='object', length=785)\n","Index(['label', 'pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6',\n","       'pixel7', 'pixel8', 'pixel9',\n","       ...\n","       'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779', 'pixel780',\n","       'pixel781', 'pixel782', 'pixel783', 'pixel784'],\n","      dtype='object', length=785)\n","(60000, 785)\n","(10000, 785)\n","Min value of train dataset is 0\n","Min value of test dataset is 0\n","Max value of train dataset is 255\n","Max value of test dataset is 255\n"]}],"source":["print(train_data.columns)\n","print(test_data.columns)\n","print(train_data.shape)\n","print(test_data.shape)\n","# excluding the label column\n","print(f\"Min value of train dataset is {train_data.iloc[0].min()}\\nMin value of test dataset is {test_data.iloc[0].min()}\")\n","print(f\"Max value of train dataset is {train_data.iloc[0].max()}\\nMax value of test dataset is {test_data.iloc[0].max()}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocess the data \n","* Normalise values to be in range [0-1]\n","* Convert the image to be in shape 28, 28 for our model"]},{"cell_type":"code","execution_count":143,"metadata":{"execution":{"iopub.execute_input":"2023-04-03T12:51:47.902211Z","iopub.status.busy":"2023-04-03T12:51:47.901554Z","iopub.status.idle":"2023-04-03T12:51:48.116361Z","shell.execute_reply":"2023-04-03T12:51:48.115330Z","shell.execute_reply.started":"2023-04-03T12:51:47.902174Z"},"trusted":true},"outputs":[],"source":["def preprocess(data):\n","    images = data.iloc[:, 1:]/255\n","    labels = data['label']\n","    return images, labels\n","    \n","train_images, train_labels = preprocess(train_data)\n","test_images, test_labels = preprocess(test_data)"]},{"cell_type":"code","execution_count":144,"metadata":{"execution":{"iopub.execute_input":"2023-04-03T12:51:48.118763Z","iopub.status.busy":"2023-04-03T12:51:48.118370Z","iopub.status.idle":"2023-04-03T12:51:48.131349Z","shell.execute_reply":"2023-04-03T12:51:48.129982Z","shell.execute_reply.started":"2023-04-03T12:51:48.118721Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Index(['pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6', 'pixel7',\n","       'pixel8', 'pixel9', 'pixel10',\n","       ...\n","       'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779', 'pixel780',\n","       'pixel781', 'pixel782', 'pixel783', 'pixel784'],\n","      dtype='object', length=784)\n","Index(['pixel1', 'pixel2', 'pixel3', 'pixel4', 'pixel5', 'pixel6', 'pixel7',\n","       'pixel8', 'pixel9', 'pixel10',\n","       ...\n","       'pixel775', 'pixel776', 'pixel777', 'pixel778', 'pixel779', 'pixel780',\n","       'pixel781', 'pixel782', 'pixel783', 'pixel784'],\n","      dtype='object', length=784)\n","(60000, 784)\n","(10000, 784)\n","Min value of train dataset is 0.0\n","Min value of test dataset is 0.0\n","Max value of train dataset is 1.0\n","Max value of test dataset is 1.0\n"]}],"source":["# after preprocessing\n","print(train_images.columns)\n","print(test_images.columns)\n","print(train_images.shape)\n","print(test_images.shape)\n","# excluding the label column\n","print(f\"Min value of train dataset is {train_images.iloc[0].min()}\\nMin value of test dataset is {test_images.iloc[0].min()}\")\n","print(f\"Max value of train dataset is {train_images.iloc[0].max()}\\nMax value of test dataset is {test_images.iloc[0].max()}\")"]},{"cell_type":"code","execution_count":145,"metadata":{"execution":{"iopub.execute_input":"2023-04-03T12:51:48.133876Z","iopub.status.busy":"2023-04-03T12:51:48.133453Z","iopub.status.idle":"2023-04-03T12:51:48.140477Z","shell.execute_reply":"2023-04-03T12:51:48.139653Z","shell.execute_reply.started":"2023-04-03T12:51:48.133836Z"},"trusted":true},"outputs":[],"source":["# image = np.array(train_images.iloc[0]).reshape(28,28)"]},{"cell_type":"code","execution_count":146,"metadata":{"execution":{"iopub.execute_input":"2023-04-03T12:51:48.142593Z","iopub.status.busy":"2023-04-03T12:51:48.141411Z","iopub.status.idle":"2023-04-03T12:51:48.150455Z","shell.execute_reply":"2023-04-03T12:51:48.149470Z","shell.execute_reply.started":"2023-04-03T12:51:48.142558Z"},"trusted":true},"outputs":[],"source":["# import matplotlib.pyplot as plt\n","# plt.imshow(image, cmap='gray')\n","# plt.title(\"shirt\")\n","# plt.show()"]},{"cell_type":"code","execution_count":147,"metadata":{"execution":{"iopub.execute_input":"2023-04-03T12:51:48.153892Z","iopub.status.busy":"2023-04-03T12:51:48.153457Z","iopub.status.idle":"2023-04-03T12:51:48.159504Z","shell.execute_reply":"2023-04-03T12:51:48.158375Z","shell.execute_reply.started":"2023-04-03T12:51:48.153865Z"},"trusted":true},"outputs":[],"source":["# ls=[]    \n","# for i in range(3):\n","#     ls.append(np.array([im for im in train_images.iloc[i,:]]).reshape(28,28))\n","# print(np.array(ls[0]).shape)\n","# plt.imshow(ls[1], cmap='gray')"]},{"cell_type":"code","execution_count":148,"metadata":{"execution":{"iopub.execute_input":"2023-04-03T12:51:48.166715Z","iopub.status.busy":"2023-04-03T12:51:48.164580Z","iopub.status.idle":"2023-04-03T12:51:48.171506Z","shell.execute_reply":"2023-04-03T12:51:48.170366Z","shell.execute_reply.started":"2023-04-03T12:51:48.166687Z"},"trusted":true},"outputs":[],"source":["import torchvision.transforms as transforms\n","\n","train_transform = transforms.Compose([\n","#     transforms.RandomHorizontalFlip(p=0.5),\n","#     transforms.RandomVerticalFlip(p=0.5),\n","    transforms.RandomRotation(degrees=(30, 70)),\n","])\n"]},{"cell_type":"code","execution_count":149,"metadata":{"execution":{"iopub.execute_input":"2023-04-03T12:51:48.176372Z","iopub.status.busy":"2023-04-03T12:51:48.175734Z","iopub.status.idle":"2023-04-03T12:51:48.190984Z","shell.execute_reply":"2023-04-03T12:51:48.189971Z","shell.execute_reply.started":"2023-04-03T12:51:48.176277Z"},"trusted":true},"outputs":[],"source":[" def dataloader(data, labels, batch_size=64, train=True):\n","    if data.shape[0] == len(labels):\n","        for i in range(0, data.shape[0], batch_size):\n","            batch_data = []\n","            batch_labels = []\n","            for j in range(i, min(i+batch_size, data.shape[0])):\n","                image_data = torch.tensor([im for im in data.iloc[j,:]], dtype=torch.float).reshape(28,28)\n","                if train==True:\n","                    transformed_image = train_transform(image_data.unsqueeze(dim=0)).squeeze()\n","                    batch_data.append(transformed_image)\n","                else:\n","                    batch_data.append(image_data.clone().detach())\n","                batch_labels.append(torch.tensor(labels.iloc[j]))\n","            # yield torch.tensor(batch_data), batch_labels   \n","            yield torch.cat([x.unsqueeze(0) for x in batch_data]), torch.tensor(batch_labels)\n"]},{"cell_type":"code","execution_count":150,"metadata":{"execution":{"iopub.execute_input":"2023-04-03T12:51:48.194149Z","iopub.status.busy":"2023-04-03T12:51:48.193038Z","iopub.status.idle":"2023-04-03T12:51:48.203235Z","shell.execute_reply":"2023-04-03T12:51:48.202346Z","shell.execute_reply.started":"2023-04-03T12:51:48.194112Z"},"trusted":true},"outputs":[],"source":["train_dataloader = dataloader(train_images, train_labels, train=False)\n","test_dataloader = dataloader(test_images, test_labels, train=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-03T12:51:48.205655Z","iopub.status.busy":"2023-04-03T12:51:48.204658Z"},"trusted":true},"outputs":[],"source":["# Convert the dataloader to a list\n","train_dataloader = list(train_dataloader)\n","test_dataloader = list(test_dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["len(test_dataloader)\n","len(train_dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# def calculate_dataloader_size(data_loader):\n","#     count=0\n","#     while True:\n","#         try:\n","#             next(data_loader)\n","#             count+=1\n","#         except Exception as e:\n","#             break\n","#     print(f\"size of {data_loader} is {count}\")\n","\n","# calculate_dataloader_size(train_dataloader)\n","# calculate_dataloader_size(test_dataloader)"]},{"cell_type":"markdown","metadata":{},"source":["# View Images"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import matplotlib.pyplot as plt\n","torch.manual_seed(42)\n","fig = plt.figure(figsize=(9,9))\n","rows, cols = 5, 5\n","for i in range(1, rows*cols+1):\n","    random_idx = torch.randint(0, len(train_dataloader), size=[1]).item()\n","    random_idx1 = torch.randint(0, 64, size=[1]).item()\n","    img, label = train_dataloader[random_idx]\n","    fig.add_subplot(rows, cols, i)\n","    plt.imshow(img[random_idx1].squeeze(), cmap=\"gray\")\n","    plt.title(label[random_idx1].item())\n","    plt.axis(False);"]},{"cell_type":"markdown","metadata":{},"source":["# CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class FashionMNISTModelV1(nn.Module):\n","    \n","    def __init__(self):\n","        super().__init__()\n","        self.block1 = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=1),\n","            nn.ReLU()\n","        )\n","        self.block2 = nn.Sequential(\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2)\n","        )\n","        self.block3 = nn.Sequential(\n","            nn.Conv2d(in_channels=64, out_channels=84, kernel_size=5, stride=1, padding=1),\n","            nn.ReLU()\n","        )\n","        self.block4 = nn.Sequential(\n","            nn.Conv2d(in_channels=84, out_channels=100, kernel_size=5, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2)\n","        )\n","        self.block5 = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(in_features=1600, out_features=10),\n","            #nn.Softmax(dim=1)\n","        )\n","       \n","\n","    def forward(self, x):\n","        x = self.block1(x)\n","        x = self.block2(x)\n","        x = self.block3(x)\n","        x = self.block4(x)\n","        x = self.block5(x)\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# modular train_step\n","from tqdm.auto import tqdm\n","def train_step(\n","    model: torch.nn.Module,\n","    dataloader,\n","    loss_fn: torch.nn.Module,\n","    optimizer: torch.optim.Optimizer,\n","    device:torch.device\n","):\n","    # Put model in train mode\n","    model.train()\n","    \n","    # Setup loss and accuracy\n","    train_loss, train_acc = 0, 0\n","    \n","    # Loop throught the data\n","    for batch, (X, y) in enumerate(tqdm(dataloader)):\n","        # Send data to device gpu or cpu\n","        X, y = X.to(device), y.to(device)\n","        \n","        # 1. Forward pass\n","        y_pred = model.forward(X.unsqueeze(dim=1))\n","        \n","        # 2. Calculate loss\n","        loss = loss_fn(y_pred, y)\n","        train_loss += loss.item()\n","        \n","        # 3. Optimizer zero grad\n","        optimizer.zero_grad()\n","        \n","        # 4. Loss backward\n","        loss.backward()\n","        \n","        # 5. Optimizer step\n","        optimizer.step()\n","        \n","        # Calculate accuracy across all batches\n","        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n","        train_acc += (y_pred_class == y).sum().item()/ len(y_pred)\n","        \n","    train_loss = train_loss/len(dataloader)\n","    train_acc = train_acc/len(dataloader)\n","    \n","    return train_loss, train_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","#  create test step\n","def test_step(model: torch.nn.Module,\n","    dataloader,\n","    loss_fn: torch.nn.Module,\n","    device: torch.device\n","):\n","    # Put model in eval mode\n","    model.eval()\n","    \n","    # Setup test loss and accuracy\n","    test_loss, test_acc = 0, 0\n","    \n","    # Inference mode or with torch.no_grad()\n","    with torch.inference_mode():\n","        # Loop through data\n","        for batch, (X, y) in enumerate(dataloader):\n","            # Send code to device\n","            X , y = X.to(device), y.to(device)\n","        \n","            # 1. Forward pass\n","            test_pred = model.forward(X.unsqueeze(dim=1))\n","            \n","            # 2. Calculate loss\n","            loss = loss_fn(test_pred, y)\n","            test_loss += loss.item()\n","            \n","            # 3. Calculate accuracy\n","            test_pred_labels = test_pred.argmax(dim=1)\n","            test_acc += (test_pred_labels == y).sum().item() / len(test_pred_labels)\n","            \n","    # Adjust metrics to get average loss and accuracy per batch \n","    test_loss = test_loss / len(dataloader)\n","    test_acc = test_acc / len(dataloader)\n","    return test_loss, test_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def train(\n","    model: torch.nn.Module,\n","    train_dataloader,\n","    test_dataloader,\n","    optimizer: torch.optim.Optimizer,\n","    loss_fn: torch.nn.Module,\n","    epochs: int,\n","    device: torch.device     \n","):\n","    # Create empty results dictionary\n","    results = {\"train_loss\": [],\n","        \"train_acc\": [],\n","        \"test_loss\": [],\n","        \"test_acc\": []\n","    }\n","    \n","    # Loop through data or epochs\n","    for epoch in range(epochs):\n","        train_loss, train_acc = train_step(model=model,\n","                                          dataloader=train_dataloader,\n","                                          loss_fn=loss_fn,\n","                                          optimizer=optimizer,\n","                                          device=device)\n","        \n","        # Test the model on unseen data\n","        test_loss, test_acc = test_step(model=model,\n","                                       dataloader=test_dataloader,\n","                                        loss_fn=loss_fn,\n","                                        device=device\n","                                       )\n","        \n","        # Print the loss and accuracy\n","        print(f\"Epoch {epoch+1} | \",\n","              f\"Train_loss {train_loss:.4f} | \",\n","              f\"Train_acc {train_acc:.4f} | \",\n","              f\"Test_loss {test_loss:.4f} | \",\n","              f\"Test_acc {test_acc:.4f}\"\n","        )\n","        \n","        # update the results\n","        results[\"train_loss\"].append(train_loss)\n","        results[\"train_acc\"].append(train_acc)\n","        results[\"test_loss\"].append(test_loss)\n","        results[\"test_acc\"].append(test_acc)\n","        \n","    return results"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from pathlib import Path\n","def save_model(model: torch.nn.Module,\n","               target_dir: str,\n","               model_name: str):\n","    # Create target directory\n","    target_dir_path = Path(target_dir)\n","    target_dir_path.mkdir(parents=True,\n","                        exist_ok=True)\n","\n","    # Create model save path\n","    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n","    model_save_path = target_dir_path / model_name\n","\n","    # Save the model state_dict()\n","    print(f\"[INFO] Saving model to: {model_save_path}\")\n","    torch.save(obj=model.state_dict(),\n","             f=model_save_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from timeit import default_timer as timer\n","def initiate_training(lr_degrade=False):\n","    # Set random seeds\n","    torch.manual_seed(42) \n","    torch.cuda.manual_seed(42)\n","    \n","    # Set up device\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    print(f\"Avilable device is {device}\")\n","    \n","    # Set number of epochs\n","    EPOCHS = 15\n","\n","    # Create model instance\n","    model_1 = FashionMNISTModelV1().to(device)\n","    \n","    # Setup loss function and optimizer\n","    loss_fn = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(params=model_1.parameters(), lr=0.01) \n","\n","    # Start the timer \n","    start_time = timer()\n","    \n","    # Train model_0 \n","    model_1_results = train(model=model_1, \n","                            train_dataloader=train_dataloader,\n","                            test_dataloader=test_dataloader,\n","                            optimizer=optimizer,\n","                            loss_fn=loss_fn, \n","                            epochs=EPOCHS,\n","                            device=device)\n","\n","    # End the timer and print out how long it took\n","    end_time = timer()\n","    \n","    print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")\n","\n","    # Save the model\n","    save_model(model=model_1,\n","               target_dir=\"\",\n","               model_name=\"FashionMNIST_CNN.pth\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["initiate_training()"]},{"cell_type":"markdown","metadata":{},"source":["* lr 0.1 for 5 epoch\n","* lr 0.01 for 5 epochs\n","* lr 0.001 for 5 epochs\n","* lr 0.0001 for 5epochs"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from tqdm.auto import tqdm\n","def test_model(model):\n","\n","    # Make predictions on the entire test dataset\n","    test_preds = []\n","    model.eval()\n","    \n","    with torch.inference_mode():\n","      # Loop through the batches in the test dataloader\n","      for X, y in tqdm(test_dataloader):\n","        X, y = X.to(device), y.to(device)\n","        # Pass the data through the model\n","        test_logits = model(X.unsqueeze(dim=1))\n","\n","        # Convert the pred logits to pred probs\n","        pred_probs = torch.softmax(test_logits, dim=1)\n","\n","        # Convert the pred probs into pred labels\n","        pred_labels = torch.argmax(pred_probs, dim=1)\n","\n","        # Add the pred labels to test preds list\n","        test_preds.append(pred_labels)\n","\n","    # Concatenate the test preds and put them on the CPU\n","    test_preds = torch.cat(test_preds).cpu()\n","    return test_preds"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Test the model\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","model = FashionMNISTModelV1().to(device)\n","model.load_state_dict(torch.load('FashionMNIST_CNN.pth'))\n","\n","test_preds = test_model(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_truth = torch.cat([y for X, y in test_dataloader])\n","test_truth\n","print(len(test_preds))\n","print(len(test_truth))\n","print(test_preds.shape, test_truth.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","from torchmetrics import ConfusionMatrix\n","from mlxtend.plotting import plot_confusion_matrix\n","class_name = [0,1,2,3,4,5,6,7,8,9]\n","# Setup confusion matrix instance\n","confmat = ConfusionMatrix(num_classes=len(class_name) ,task=\"multiclass\")\n","confmat_tensor = confmat(preds=test_preds,\n","                         target=test_truth)\n","\n","# Plot the confusion matrix\n","fig, ax = plot_confusion_matrix(\n","    conf_mat=confmat_tensor.numpy(), # matplotlib likes working with NumPy\n","    class_names=class_name,\n","    figsize=(10, 7)\n",")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
